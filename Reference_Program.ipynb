{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPa1icAT0v/6zpUzkTxbU3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swankystark/Google-Tunix-Hack/blob/main/Reference_Program.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reference Program**"
      ],
      "metadata": {
        "id": "RyiKPwTTgZEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_hbm_usage():\n",
        "  \"\"\"Displays memory usage per device.\"\"\"\n",
        "  fmt_size = functools.partial(humanize.naturalsize, binary=True)\n",
        "\n",
        "  for d in jax.local_devices():\n",
        "    stats = d.memory_stats()\n",
        "    used = stats[\"bytes_in_use\"]\n",
        "    limit = stats[\"bytes_limit\"]\n",
        "    print(f\"Using {fmt_size(used)} / {fmt_size(limit)} ({used/limit:%}) on {d}\")"
      ],
      "metadata": {
        "id": "UKprffS0hfmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is useful because:\n",
        "\n",
        ">Fine-tuning Gemma + LoRA + GRPO is memory heavy.\n",
        "\n",
        "> If memory usage exceeds limits → TPU crashes.\n",
        "\n",
        "> This function lets you check memory usage anytime during the notebook."
      ],
      "metadata": {
        "id": "lmSI8MgQhmsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ele in train_dataset[:1]:\n",
        "  pprint(ele)\n"
      ],
      "metadata": {
        "id": "Whd4muIWiJJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a sanity check to confirm:\n",
        "\n",
        "*   the template is correct\n",
        "\n",
        "*   prompts look correct\n",
        "\n",
        "\n",
        "*   answer extraction worked\n",
        "\n",
        "*   the dataset pipeline is producing the right format\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H-7ZrlR3iStq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /tmp/content/intermediate_ckpt/* -rf\n",
        "\n",
        "!rm /tmp/content/ckpts/* -rf\n",
        "\n",
        "if model_family == \"gemma2\":\n",
        "  params = params_lib.load_and_format_params(\n",
        "      os.path.join(kaggle_ckpt_path, \"gemma2-2b-it\")\n",
        "  )\n",
        "  gemma = gemma_lib.Transformer.from_params(params, version=\"2-2b-it\")\n",
        "  checkpointer = ocp.StandardCheckpointer()\n",
        "  _, state = nnx.split(gemma)\n",
        "  checkpointer.save(os.path.join(INTERMEDIATE_CKPT_DIR, \"state\"), state)\n",
        "  checkpointer.wait_until_finished()\n",
        "  del params\n",
        "  del gemma\n",
        "  del state\n",
        "  gc.collect()\n"
      ],
      "metadata": {
        "id": "TLNsklzPi98V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A checkpoint is a saved version of your model’s weights (parameters) at a specific moment during training.\n",
        "\n",
        "\n",
        "1.   Before training → load checkpoint of pretrained Gemma\n",
        "\n",
        "2.   During training → save checkpoints every few steps\n",
        "\n",
        "3.   After training → final checkpoint contains the tuned model\n",
        "\n"
      ],
      "metadata": {
        "id": "hbkWUNvDjE1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# V1: TPU Check\n",
        "print(f\"JAX devices: {jax.devices()}\")\n",
        "assert jax.device_count() > 0, \"No TPU found!\"\n"
      ],
      "metadata": {
        "id": "-SG8GtzPjpTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "jax.devices() returns a list of all available compute devices: CPU, GPU, TPU.\n",
        "\n",
        "> Printing it helps you verify: “Am I really on a TPU notebook / Colab / Kaggle with TPU?”\n",
        "\n",
        "jax.device_count() gives how many devices there are."
      ],
      "metadata": {
        "id": "IilerArrkKn1"
      }
    }
  ]
}